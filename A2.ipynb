{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Machine Learning with Scikit-Learn\n",
    "**Iftekhar Rafi B00871031**\n",
    "\n",
    "**Abdulla Sadoun B00900541**\n",
    "\n",
    "## Question 0: Revisiting Your Dataset (A1Q1)\n",
    "\n",
    "### a) Dataset Selection\n",
    "For this assignment, We have selected the **CSE-CIC-IDS2018** dataset from the **Canadian Institute for Cybersecurity at the University of New Brunswick** also used for Assignment 1. This dataset is well-suited for analyzing **network intrusion detection**. Several methods of network intrusion have been explored in this research and subsequent dataset. I will be focusing on the dataset collected from **brute-force attack scenarios** as described in the research. The data is taken from their processed dataset for Wednesday, 14 February as described below.\n",
    "\n",
    "#### Dataset Details\n",
    "- **Source**: [CICIDS 2018 Dataset](https://www.unb.ca/cic/datasets/ids-2018.html)\n",
    "- **Types of Attacks Covered**: Brute-force attacks (FTP and SSH)\n",
    "\n",
    "| Attacker                     | Victim                          | Attack Name      | Date          | Attack Start Time | Attack Finish Time |\n",
    "|------------------------------|---------------------------------|------------------|---------------|-------------------|--------------------|\n",
    "| 172.31.70.4 (Valid IP:18.221.219.4) | 172.31.69.25 (Valid IP:18.217.21.148) | FTP-BruteForce   | Wed-14-02-2018 | 10:32             | 12:09              |\n",
    "| 172.31.70.6 (Valid IP:13.58.98.64)  | 18.217.21.148- 172.31.69.25          | SSH-BruteForce   | Wed-14-02-2018 | 14:01             | 15:31              |\n",
    "\n",
    "\n",
    "### b) Dataset Loading\n",
    "The dataset was loaded into a Pandas DataFrame using the following code:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 80 columns):\n",
      " #   Column             Non-Null Count    Dtype  \n",
      "---  ------             --------------    -----  \n",
      " 0   Dst Port           1048575 non-null  int64  \n",
      " 1   Protocol           1048575 non-null  int64  \n",
      " 2   Timestamp          1048575 non-null  object \n",
      " 3   Flow Duration      1048575 non-null  int64  \n",
      " 4   Tot Fwd Pkts       1048575 non-null  int64  \n",
      " 5   Tot Bwd Pkts       1048575 non-null  int64  \n",
      " 6   TotLen Fwd Pkts    1048575 non-null  int64  \n",
      " 7   TotLen Bwd Pkts    1048575 non-null  int64  \n",
      " 8   Fwd Pkt Len Max    1048575 non-null  int64  \n",
      " 9   Fwd Pkt Len Min    1048575 non-null  int64  \n",
      " 10  Fwd Pkt Len Mean   1048575 non-null  float64\n",
      " 11  Fwd Pkt Len Std    1048575 non-null  float64\n",
      " 12  Bwd Pkt Len Max    1048575 non-null  int64  \n",
      " 13  Bwd Pkt Len Min    1048575 non-null  int64  \n",
      " 14  Bwd Pkt Len Mean   1048575 non-null  float64\n",
      " 15  Bwd Pkt Len Std    1048575 non-null  float64\n",
      " 16  Flow Byts/s        1046298 non-null  float64\n",
      " 17  Flow Pkts/s        1048575 non-null  float64\n",
      " 18  Flow IAT Mean      1048575 non-null  float64\n",
      " 19  Flow IAT Std       1048575 non-null  float64\n",
      " 20  Flow IAT Max       1048575 non-null  int64  \n",
      " 21  Flow IAT Min       1048575 non-null  int64  \n",
      " 22  Fwd IAT Tot        1048575 non-null  int64  \n",
      " 23  Fwd IAT Mean       1048575 non-null  float64\n",
      " 24  Fwd IAT Std        1048575 non-null  float64\n",
      " 25  Fwd IAT Max        1048575 non-null  int64  \n",
      " 26  Fwd IAT Min        1048575 non-null  int64  \n",
      " 27  Bwd IAT Tot        1048575 non-null  int64  \n",
      " 28  Bwd IAT Mean       1048575 non-null  float64\n",
      " 29  Bwd IAT Std        1048575 non-null  float64\n",
      " 30  Bwd IAT Max        1048575 non-null  int64  \n",
      " 31  Bwd IAT Min        1048575 non-null  int64  \n",
      " 32  Fwd PSH Flags      1048575 non-null  int64  \n",
      " 33  Bwd PSH Flags      1048575 non-null  int64  \n",
      " 34  Fwd URG Flags      1048575 non-null  int64  \n",
      " 35  Bwd URG Flags      1048575 non-null  int64  \n",
      " 36  Fwd Header Len     1048575 non-null  int64  \n",
      " 37  Bwd Header Len     1048575 non-null  int64  \n",
      " 38  Fwd Pkts/s         1048575 non-null  float64\n",
      " 39  Bwd Pkts/s         1048575 non-null  float64\n",
      " 40  Pkt Len Min        1048575 non-null  int64  \n",
      " 41  Pkt Len Max        1048575 non-null  int64  \n",
      " 42  Pkt Len Mean       1048575 non-null  float64\n",
      " 43  Pkt Len Std        1048575 non-null  float64\n",
      " 44  Pkt Len Var        1048575 non-null  float64\n",
      " 45  FIN Flag Cnt       1048575 non-null  int64  \n",
      " 46  SYN Flag Cnt       1048575 non-null  int64  \n",
      " 47  RST Flag Cnt       1048575 non-null  int64  \n",
      " 48  PSH Flag Cnt       1048575 non-null  int64  \n",
      " 49  ACK Flag Cnt       1048575 non-null  int64  \n",
      " 50  URG Flag Cnt       1048575 non-null  int64  \n",
      " 51  CWE Flag Count     1048575 non-null  int64  \n",
      " 52  ECE Flag Cnt       1048575 non-null  int64  \n",
      " 53  Down/Up Ratio      1048575 non-null  int64  \n",
      " 54  Pkt Size Avg       1048575 non-null  float64\n",
      " 55  Fwd Seg Size Avg   1048575 non-null  float64\n",
      " 56  Bwd Seg Size Avg   1048575 non-null  float64\n",
      " 57  Fwd Byts/b Avg     1048575 non-null  int64  \n",
      " 58  Fwd Pkts/b Avg     1048575 non-null  int64  \n",
      " 59  Fwd Blk Rate Avg   1048575 non-null  int64  \n",
      " 60  Bwd Byts/b Avg     1048575 non-null  int64  \n",
      " 61  Bwd Pkts/b Avg     1048575 non-null  int64  \n",
      " 62  Bwd Blk Rate Avg   1048575 non-null  int64  \n",
      " 63  Subflow Fwd Pkts   1048575 non-null  int64  \n",
      " 64  Subflow Fwd Byts   1048575 non-null  int64  \n",
      " 65  Subflow Bwd Pkts   1048575 non-null  int64  \n",
      " 66  Subflow Bwd Byts   1048575 non-null  int64  \n",
      " 67  Init Fwd Win Byts  1048575 non-null  int64  \n",
      " 68  Init Bwd Win Byts  1048575 non-null  int64  \n",
      " 69  Fwd Act Data Pkts  1048575 non-null  int64  \n",
      " 70  Fwd Seg Size Min   1048575 non-null  int64  \n",
      " 71  Active Mean        1048575 non-null  float64\n",
      " 72  Active Std         1048575 non-null  float64\n",
      " 73  Active Max         1048575 non-null  int64  \n",
      " 74  Active Min         1048575 non-null  int64  \n",
      " 75  Idle Mean          1048575 non-null  float64\n",
      " 76  Idle Std           1048575 non-null  float64\n",
      " 77  Idle Max           1048575 non-null  int64  \n",
      " 78  Idle Min           1048575 non-null  int64  \n",
      " 79  Label              1048575 non-null  object \n",
      "dtypes: float64(24), int64(54), object(2)\n",
      "memory usage: 640.0+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14/02/2018 08:31:01</td>\n",
       "      <td>112641719</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56320859.5</td>\n",
       "      <td>139.300036</td>\n",
       "      <td>56320958</td>\n",
       "      <td>56320761</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14/02/2018 08:33:50</td>\n",
       "      <td>112641466</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56320733.0</td>\n",
       "      <td>114.551299</td>\n",
       "      <td>56320814</td>\n",
       "      <td>56320652</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14/02/2018 08:36:39</td>\n",
       "      <td>112638623</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56319311.5</td>\n",
       "      <td>301.934596</td>\n",
       "      <td>56319525</td>\n",
       "      <td>56319098</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>14/02/2018 08:40:13</td>\n",
       "      <td>6453966</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>1239</td>\n",
       "      <td>2273</td>\n",
       "      <td>744</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>14/02/2018 08:40:23</td>\n",
       "      <td>8804066</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>1143</td>\n",
       "      <td>2209</td>\n",
       "      <td>744</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dst Port  Protocol            Timestamp  Flow Duration  Tot Fwd Pkts  \\\n",
       "0         0         0  14/02/2018 08:31:01      112641719             3   \n",
       "1         0         0  14/02/2018 08:33:50      112641466             3   \n",
       "2         0         0  14/02/2018 08:36:39      112638623             3   \n",
       "3        22         6  14/02/2018 08:40:13        6453966            15   \n",
       "4        22         6  14/02/2018 08:40:23        8804066            14   \n",
       "\n",
       "   Tot Bwd Pkts  TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  \\\n",
       "0             0                0                0                0   \n",
       "1             0                0                0                0   \n",
       "2             0                0                0                0   \n",
       "3            10             1239             2273              744   \n",
       "4            11             1143             2209              744   \n",
       "\n",
       "   Fwd Pkt Len Min  ...  Fwd Seg Size Min  Active Mean  Active Std  \\\n",
       "0                0  ...                 0          0.0         0.0   \n",
       "1                0  ...                 0          0.0         0.0   \n",
       "2                0  ...                 0          0.0         0.0   \n",
       "3                0  ...                32          0.0         0.0   \n",
       "4                0  ...                32          0.0         0.0   \n",
       "\n",
       "   Active Max  Active Min   Idle Mean    Idle Std  Idle Max  Idle Min   Label  \n",
       "0           0           0  56320859.5  139.300036  56320958  56320761  Benign  \n",
       "1           0           0  56320733.0  114.551299  56320814  56320652  Benign  \n",
       "2           0           0  56319311.5  301.934596  56319525  56319098  Benign  \n",
       "3           0           0         0.0    0.000000         0         0  Benign  \n",
       "4           0           0         0.0    0.000000         0         0  Benign  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Description of the Dataset\n",
    "\n",
    "The dataset consists of network traffic data collected on **February 14, 2018**, as part of the **CSE-CIC-IDS2018** dataset. It captures various network activities, including normal (benign) traffic and brute-force attacks targeting FTP and SSH services. The dataset includes **1,048,575 rows** and **80 columns**, each representing different characteristics of the network flows.\n",
    "\n",
    "Here is a breakdown of the dataset:\n",
    "- **Total Number of Records**: 1,048,575\n",
    "- **Total Number of Features (Columns)**: 80\n",
    "- **Types of Data**:\n",
    "  - **Numeric Features**: Most of the columns are numeric, such as packet counts, flow durations, and packet sizes. These can help analyze the behavior of network traffic.\n",
    "  - **Categorical Features**: The dataset includes a column labeled \"Label,\" which identifies whether a given flow is benign or part of a specific attack type.\n",
    "\n",
    "### Key Features in the Dataset\n",
    "- **Flow Duration**: Measures how long a network flow lasted.\n",
    "- **Total Forward and Backward Packets** (`Tot Fwd Pkts`, `Tot Bwd Pkts`): Counts the number of packets sent in the forward and backward directions.\n",
    "- **Packet Length Statistics**: Provides information about the maximum, minimum, average, and standard deviation of packet lengths in both directions.\n",
    "- **Flow Rate (`Flow Byts/s`, `Flow Pkts/s`)**: Indicates the number of bytes or packets transmitted per second during a flow.\n",
    "- **Inter-Arrival Time**: Measures the time between consecutive packets.\n",
    "- **Flags**: Various TCP flags, such as `SYN`, `ACK`, and `RST`, are used to indicate specific network conditions.\n",
    "- **Active and Idle Times**: Represents the time intervals when the flow was actively transmitting data and when it was idle.\n",
    "\n",
    "### Dataset Usage\n",
    "The data can be used to detect and analyze network intrusions, specifically **brute-force attacks**. By examining patterns in traffic, such as sudden spikes in flow rates or repeated login attempts, it is possible to identify suspicious behaviors indicative of an ongoing attack.\n",
    "\n",
    "### Example Records\n",
    "Each row in the dataset represents a network flow, containing information like the flow's duration, the total number of packets, and the size of packets transmitted in both directions. The dataset also provides a label indicating whether the flow is normal (benign) or an attack.\n",
    "\n",
    "Overall, this dataset is useful for tasks such as detecting brute-force attacks and understanding the characteristics of network traffic during different types of events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Utilizing Machine Learning (15 points)\n",
    "\n",
    "### Experiemting with 3 machine learning Models, for each model:\n",
    "#### a) Train your models by applying an appropriate training/test split.  \n",
    "#### b) If applicable to that model, explore how using regularization can improve it. \n",
    "#### c) For each model, create visuals that highlight interesting aspects of your model and the results. \n",
    "#### d) For classification models, obtain the classification report and the confusion matrix. Comment on the results. 5. If applicable, calculate and visualize feature importance.\n",
    "\n",
    "We first started by preprocessing the data, we have tried running but have noticed that there are errors due to infinity and NaN values in X, so I replaced the infinite values that are outside of the float range with NaN and then used an imputer to replace the NaN values with averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Prepare the data\n",
    "X = df.drop(columns=['Timestamp', 'Label'])\n",
    "y = df['Label']\n",
    "\n",
    "# infinity x values fix (replaced with nan)\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Fill missing values with the mean of the column (filling nan values)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123, test_size=0.25, stratify=y) # 75% training and 25% test (used by professor)\n",
    "\n",
    "# Reducing the size to avoid vm crash\n",
    "X_train, y_train = X_train[:100000], y_train[:100000]  # Use only the first 100k samples for training to avoid crashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have also came to the conclusion that given our limited hardware capabilites, we will not be able to use as big of a dataset as we thought we could, our initial dataset had 1.5M records initially but we had to limited it down to XXXXXXX to avoid crashing  ##<---[TEST HERE IFTEKHAR]##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression model\n",
    "\n",
    "I have chosen to start with this model as it is the most used.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is 98.78 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "# lr_model_1 = LogisticRegression(max_iter=1000)\n",
    "# r_model_1 = LogisticRegression(max_iter=2000) # increased max_iter to 2000 to avoid convergence warning\n",
    "#lr_model_1 = LogisticRegression(max_iter=2000, solver='saga') # Initialize the logistic regression model with increased max_iter and saga solver as 2000 didnt work\n",
    "lr_model_1 = LogisticRegression(max_iter=1000, solver='liblinear') # trying this again after reducing the training data size \n",
    "\n",
    "# Train the model\n",
    "lr_model_1.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "accuracy = lr_model_1.score(X_test, y_test)\n",
    "print('The test accuracy is {0:5.2f} %'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Benign       0.99      0.99      0.99    166907\n",
      "FTP-BruteForce       0.98      1.00      0.99     48340\n",
      "SSH-Bruteforce       0.99      0.96      0.98     46897\n",
      "\n",
      "      accuracy                           0.99    262144\n",
      "     macro avg       0.99      0.98      0.99    262144\n",
      "  weighted avg       0.99      0.99      0.99    262144\n",
      "\n",
      "Confusion Matrix:\n",
      "[[165408    984    515]\n",
      " [     1  48339      0]\n",
      " [  1695     13  45189]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred = lr_model_1.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "# lr_model = LinearRegression() #uses the closed-form solution\n",
    "# print(lr_model)\n",
    "# lr_model.fit(X_train, y_train)\n",
    "# y_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "Model often used for high-dimensional data and includes feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy of the Random Forest model is 100.00 %\n",
      "Classification Report for Random Forest:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Benign       1.00      1.00      1.00    166907\n",
      "FTP-BruteForce       1.00      1.00      1.00     48340\n",
      "SSH-Bruteforce       1.00      1.00      1.00     46897\n",
      "\n",
      "      accuracy                           1.00    262144\n",
      "     macro avg       1.00      1.00      1.00    262144\n",
      "  weighted avg       1.00      1.00      1.00    262144\n",
      "\n",
      "Confusion Matrix for Random Forest:\n",
      "[[166905      1      1]\n",
      " [     0  48340      0]\n",
      " [     1      5  46891]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_rf = rf_model.score(X_test, y_test)\n",
    "print('The test accuracy of the Random Forest model is {0:5.2f} %'.format(accuracy_rf * 100))\n",
    "\n",
    "print(\"Classification Report for Random Forest:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "print(\"Confusion Matrix for Random Forest:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "Model that is often used when the classes are not linearly separable, but are altered greatly from scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy of the Support Vector Machine model is 64.22 %\n",
      "Classification Report for SVM:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Benign       0.80      0.58      0.67    166907\n",
      "FTP-BruteForce       0.98      1.00      0.99     48340\n",
      "SSH-Bruteforce       0.25      0.50      0.34     46897\n",
      "\n",
      "      accuracy                           0.64    262144\n",
      "     macro avg       0.68      0.69      0.67    262144\n",
      "  weighted avg       0.74      0.64      0.67    262144\n",
      "\n",
      "Confusion Matrix for SVM:\n",
      "[[96551   739 69617]\n",
      " [    0 48340     0]\n",
      " [23432     5 23460]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm_model = SVC(kernel='linear', max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "# Evaluate the model\n",
    "svm_model = svm_model.score(X_test, y_test)\n",
    "print('The test accuracy of the Support Vector Machine model is {0:5.2f} %'.format(svm_model * 100))\n",
    "\n",
    "print(\"Classification Report for SVM:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "print(\"Confusion Matrix for SVM:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy of the K-Nearest Neighbors model is 99.94 %\n",
      "Classification Report for K-Nearest Neighbors:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Benign       1.00      1.00      1.00    166907\n",
      "FTP-BruteForce       1.00      1.00      1.00     48340\n",
      "SSH-Bruteforce       1.00      1.00      1.00     46897\n",
      "\n",
      "      accuracy                           1.00    262144\n",
      "     macro avg       1.00      1.00      1.00    262144\n",
      "  weighted avg       1.00      1.00      1.00    262144\n",
      "\n",
      "Confusion Matrix for K-Nearest Neighbors:\n",
      "[[166805     25     77]\n",
      " [     1  48339      0]\n",
      " [    33     20  46844]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize the KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the KNN model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_knn = knn_model.score(X_test, y_test)\n",
    "print('The test accuracy of the K-Nearest Neighbors model is {0:5.2f} %'.format(accuracy_knn * 100))\n",
    "\n",
    "print(\"Classification Report for K-Nearest Neighbors:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "print(\"Confusion Matrix for K-Nearest Neighbors:\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
